{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8JILDxrsgPY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import normalize\n",
    "#from google.colab import drive                # IF you are using COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKixUdldszgx"
   },
   "outputs": [],
   "source": [
    "# Use this if you are working on COLAB\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HApL-cvBs1Ah"
   },
   "outputs": [],
   "source": [
    "def extract_data(x_data_filepath, y_data_filepath):\n",
    "    X = np.load(x_data_filepath)\n",
    "    y = np.load(y_data_filepath)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_mCkbFV1bq9"
   },
   "outputs": [],
   "source": [
    "def data_visualization(images,labels):\n",
    "    \"\"\"\n",
    "    Visualize 6 pictures per class using your prefered visualization library (matplotlib, etc)\n",
    "\n",
    "    Args:\n",
    "        images: training images in shape (num_images,3,image_H,image_W)\n",
    "        labels: training labels in shape (num_images,)\n",
    "    \"\"\"\n",
    "    # Extract the indices of 6 images of each class from labels\n",
    "    lst_labels = [int(x) for x in labels]\n",
    "    label_0 = [index for index, value in enumerate(lst_labels) if value == 0][:6]\n",
    "    label_1 = [index for index, value in enumerate(lst_labels) if value == 1][:6]\n",
    "    label_2 = [index for index, value in enumerate(lst_labels) if value == 2][:6]\n",
    "    label_3 = [index for index, value in enumerate(lst_labels) if value == 3][:6]\n",
    "    label_4 = [index for index, value in enumerate(lst_labels) if value == 4][:6]\n",
    "    y = [label_0,label_1, label_2, label_3, label_4]\n",
    "    for i in range(5):\n",
    "        for j in y[i]:\n",
    "            plt.figure()\n",
    "            plt.imshow(images[j][:,:,:].T.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnttiXoks2sn"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Extracting and loading data\n",
    "############################################################\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.len = len(X)           \n",
    "        if torch.cuda.is_available():\n",
    "            self.x_data = torch.from_numpy(X).float().cuda()\n",
    "            self.y_data = torch.from_numpy(y).long().cuda()\n",
    "        else:\n",
    "            self.x_data = torch.from_numpy(X).float()\n",
    "            self.y_data = torch.from_numpy(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2LxFInms4ks"
   },
   "outputs": [],
   "source": [
    "def create_validation(x_train,y_train):\n",
    "    \"\"\"\n",
    "    Randomly choose 20 percent of the training data as validation data.\n",
    "\n",
    "    Args:\n",
    "        x_train: training images in shape (num_images,3,image_H,image_W)\n",
    "        y_train: training labels in shape (num_images,)\n",
    "    Returns:\n",
    "        new_x_train: training images in shape (0.8*num_images,3,image_H,image_W)\n",
    "        new_y_train: training labels in shape (0.8*num_images,)\n",
    "        x_val: validation images in shape (0.2*num_images,3,image_H,image_W)\n",
    "        y_val: validation labels in shape (0.2*num_images,)\n",
    "    \"\"\"\n",
    "    data = Dataset(x_train,y_train)\n",
    "    train_size = int(np.floor(0.8 * len(data)))\n",
    "    indices= list(range(len(data)))\n",
    "    valid_size = len(data) - train_size\n",
    "    np.random.shuffle(indices)\n",
    "    train_mapping=indices[valid_size:]\n",
    "    valid_mapping=indices[:valid_size]\n",
    "    new_x_train = data.x_data[train_mapping]\n",
    "    x_val = data.x_data[valid_mapping]\n",
    "    new_y_train = data.y_data[train_mapping]\n",
    "    y_val = data.y_data[valid_mapping]\n",
    "    \n",
    "    return new_x_train,new_y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "812xDSEms72t"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Feed Forward Neural Network\n",
    "############################################################\n",
    "class FeedForwardNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.fc1 as the variable name for your first fully connected layer\n",
    "        (2) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(16320,2000)\n",
    "        self.fc2 = nn.Linear(2000,5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshaping the input to 16320*1\n",
    "        x_flatten = x.view(x.size(0),-1)\n",
    "        # Computing the output of the first feedforward layer\n",
    "        out1 = F.relu(self.fc1(x_flatten))\n",
    "        # Computing the output of the second feedforward layer\n",
    "        out = self.fc2(out1)\n",
    "        return out\n",
    "        \n",
    "    \"\"\" \n",
    "        Please do not change the functions below. \n",
    "        They will be used to test the correctness of your implementation \n",
    "    \"\"\"\n",
    "    def get_fc1_params(self):\n",
    "        return self.fc1.__repr__()\n",
    "    \n",
    "    def get_fc2_params(self):\n",
    "        return self.fc2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NXchxSvtEdz"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Convolutional Neural Network\n",
    "############################################################\n",
    "class ConvolutionalNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
    "        (2) Use self.pool1 as the variable name for your first pooling layer\n",
    "        (3) Use self.conv2 as the variable name for your second convolutional layer\n",
    "        (4) Use self.pool2 as the variable name for you second pooling layer  \n",
    "        (5) Use self.fc1 as the variable name for your first fully connected laye\n",
    "        (6) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3,stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3,stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3,stride=1, padding=0)\n",
    "        self.pool3 =nn.MaxPool2d(kernel_size = 2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(3072, 200)\n",
    "        self.fc2 = nn.Linear(200, 5)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Normalisation\n",
    "        x_numpy = x.cpu().numpy()\n",
    "        x = normalize_image(x_numpy)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.pool1(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.pool2(out)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.pool3(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "      \n",
    "    \"\"\" \n",
    "        Please do not change the functions below. \n",
    "        They will be used to test the correctness of your implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_conv1_params(self):\n",
    "        return self.conv1.__repr__()\n",
    "    \n",
    "    def get_pool1_params(self):\n",
    "        return self.pool1.__repr__()\n",
    "\n",
    "    def get_conv2_params(self):\n",
    "        return self.conv2.__repr__()\n",
    "      \n",
    "    def get_pool2_params(self):\n",
    "        return self.pool2.__repr__()\n",
    "      \n",
    "    def get_fc1_params(self):\n",
    "        return self.fc1.__repr__()\n",
    "    \n",
    "    def get_fc2_params(self):\n",
    "        return self.fc2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5hhOy6htEtC"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize each input image\n",
    "\n",
    "    Args:\n",
    "        image: the input image in shape (3,image_H,image_W)\n",
    "    Returns:\n",
    "        norimg: the normalized image in the same shape as the input\n",
    "    \"\"\"\n",
    "    np_x = image.copy()\n",
    "    # Mean per channel\n",
    "    red_mean = np.mean(np_x[0,:,:])\n",
    "    green_mean = np.mean(np_x[1,:,:])\n",
    "    blue_mean = np.mean(np_x[2,:,:])\n",
    "    # Standard Deviation per channel\n",
    "    red_std = np.std(np_x[0,:,:])\n",
    "    green_std = np.std(np_x[1,:,:])\n",
    "    blue_std = np.std(np_x[2,:,:])\n",
    "    # normalize in tensor\n",
    "    np_x[0,:,:] = (np_x[0,:,:] - red_mean)/red_std\n",
    "    np_x[1,:,:] = (np_x[1,:,:] - green_mean)/green_std\n",
    "    np_x[2,:,:] = (np_x[2,:,:] - blue_mean)/blue_std\n",
    "    norimg = torch.tensor(np_x)\n",
    "    return norimg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVRyEtmQtzn2"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Optimized Neural Network\n",
    "############################################################\n",
    "class OptimizedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(16320,10000) \n",
    "        self.fc2 = nn.Linear(10000,5000)\n",
    "        self.fc3 = nn.Linear(5000,2048)\n",
    "        self.fc4 = nn.Linear(2048,1024)\n",
    "        self.fc5 = nn.Linear(1024,512)\n",
    "        self.fc6 = nn.Linear(512,256)\n",
    "        self.fc7 = nn.Linear(256,124)\n",
    "        self.fc8 = nn.Linear(124,5)\n",
    "    def forward(self, x):\n",
    "        # Normalize the image\n",
    "        x_numpy = x.cpu().numpy()\n",
    "        x = normalize_image(x_numpy)\n",
    "        # Reshaping the input to 16320*1\n",
    "        x_flatten = x.view(x.size(0),-1)\n",
    "        out = F.relu(self.fc1(x_flatten))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = F.relu(self.fc5(out))\n",
    "        out = F.relu(self.fc6(out))\n",
    "        out = self.fc7(out)\n",
    "        return out\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQHzqYLSt-mQ"
   },
   "outputs": [],
   "source": [
    "def train_val_NN(neural_network, train_loader, validation_loader, loss_function, optimizer,num_epochs):\n",
    "    \"\"\"\n",
    "    Runs experiment on the model neural network given a train loader, loss function and optimizer and find validation \n",
    "    accuracy for each epoch given the validation_loader.\n",
    "\n",
    "    Args:\n",
    "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
    "                                                                FeedForwardNN or ConvolutionalNN,\n",
    "        train_loader (DataLoader),\n",
    "        validation_loader (DataLoader),\n",
    "        loss_function (torch.nn.CrossEntropyLoss),\n",
    "        optimizer (optim.SGD)\n",
    "        num_epochs (number of iterations)\n",
    "    Returns:\n",
    "        tuple: First position, training accuracies of each epoch formatted in an array of shape (num_epochs,1).\n",
    "               Second position, training loss of each epoch formatted in an array of shape (num_epochs,1).\n",
    "               third position, validation accuracy of each epoch formatted in an array of shape (num_epochs,1).\n",
    "               \n",
    "    \"\"\"\n",
    "    accuracy = np.zeros(shape=(num_epochs,1))\n",
    "    val_accuracy = np.zeros(shape=(num_epochs,1))\n",
    "    loss_np = np.zeros(shape=(num_epochs,1))\n",
    "    iterator = 0\n",
    "    for epoch in range(1, num_epochs+1): ## run the model for 10 epochs\n",
    "        train_loss = []\n",
    "        ## training part \n",
    "        neural_network.train()\n",
    "        correct = 0\n",
    "        acc = 0\n",
    "        val_acc = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            ## forward propagation\n",
    "            output = neural_network(data)\n",
    "            ## loss calculation\n",
    "            loss = loss_function(output, target)\n",
    "            ## backward propagation\n",
    "            loss.backward()\n",
    "            ## weight optimization\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            ## accuracy computation for each batch\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        acc = correct.item()/len(train_loader.dataset)\n",
    "        ## evaluation part \n",
    "        neural_network.eval()\n",
    "        correct = 0\n",
    "        for data, target in validation_loader:\n",
    "            output = neural_network(data)\n",
    "            loss = loss_function(output, target)\n",
    "            ## accuracy computation on validation set\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        val_acc=correct.item()/len(validation_loader.dataset)   \n",
    "        # Add values for each epoch to the arrays\n",
    "        accuracy[iterator] = acc\n",
    "        val_accuracy[iterator] = val_acc\n",
    "        loss_np[iterator] = np.mean(train_loss)\n",
    "        iterator+=1\n",
    "    torch.cuda.empty_cache()\n",
    "    return accuracy,loss_np,val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLlMhNt7vQxR"
   },
   "outputs": [],
   "source": [
    "def test_NN(neural_network, test_loader):\n",
    "  \n",
    "    \"\"\"\n",
    "    Runs experiment on the model neural network given a test loader, loss function and optimizer.\n",
    "\n",
    "    Args:\n",
    "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
    "                                                                FeedForwardNN or ConvolutionalNN,\n",
    "        test_loader (DataLoader), (make sure the loader is not shuffled)\n",
    "    Returns:\n",
    "        your predictions         \n",
    "    \"\"\"\n",
    "    neural_network.eval()\n",
    "    Preds = torch.LongTensor()\n",
    "    \n",
    "    for _, data in enumerate(test_loader):\n",
    "        data = data[0]\n",
    "        output = neural_network(data)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        Preds = torch.cat((Preds, pred), dim=0)\n",
    "        \n",
    "    return Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDQrfJXSv9iY"
   },
   "outputs": [],
   "source": [
    "# # Run Baseline FeedForward\n",
    "# ############################################# Data Preprocessing #################################################\n",
    "\n",
    "images, labels = extract_data('data\\images_train.npy', 'data\\labels_train.npy')\n",
    "x_train, y_train, x_val, y_val = create_validation(images,labels)\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "validation_dataset = torch.utils.data.TensorDataset(x_val,y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
    "\n",
    "############################################# Network Objects ######################################################\n",
    "\n",
    "num_epochs = 40\n",
    "ff_nn = FeedForwardNN()\n",
    "ff_nn.cuda()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.cuda()\n",
    "optimizer = optim.Adagrad(ff_nn.parameters(), lr=0.001)\n",
    "\n",
    "accuracy,loss_np,val_accuracy = train_val_NN(ff_nn, train_loader, validation_loader, criterion, optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DK0rXwRdv-PC"
   },
   "outputs": [],
   "source": [
    "# Run Baseline CNN\n",
    "############################################# Network Objects ######################################################\n",
    "\n",
    "num_epochs = 40\n",
    "c_nn = ConvolutionalNN()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(c_nn.parameters(), lr=0.001)\n",
    "\n",
    "accuracy,loss_np,val_accuracy = train_val_NN(c_nn, train_loader, validation_loader, criterion, optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gojhzqhrwAxk"
   },
   "outputs": [],
   "source": [
    "# # Run Baseline CNN on Normilized Images\n",
    "\n",
    "# images, labels = extract_data('data\\images_train.npy', 'data\\labels_train.npy')\n",
    "# x_train, y_train, x_val, y_val = create_validation(images,labels)\n",
    "# train_dataset = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "# validation_dataset = torch.utils.data.TensorDataset(x_val,y_val)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "# validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
    "\n",
    "# ############################################# Network Objects ######################################################\n",
    "\n",
    "# num_epochs = 40\n",
    "# c_nn = ConvolutionalNN()\n",
    "# # Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adagrad(c_nn.parameters(), lr=0.001)\n",
    "\n",
    "# accuracy,loss_np,val_accuracy = train_val_NN(c_nn, train_loader, validation_loader, criterion, optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ioni3nPfwEIE"
   },
   "outputs": [],
   "source": [
    "# Choose from one of the above models and improve its performance\n",
    "torch.cuda.empty_cache()\n",
    "images, labels = extract_data('data\\images_train.npy', 'data\\labels_train.npy')\n",
    "x_train, y_train, x_val, y_val = create_validation(images,labels)\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "validation_dataset = torch.utils.data.TensorDataset(x_val,y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
    "num_epochs = 40\n",
    "optimized_nn = OptimizedNN()\n",
    "optimized_nn = optimized_nn.cuda()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(optimized_nn.parameters(), lr=1e-4)\n",
    "# def init_normal(m):\n",
    "#     if type(m) == nn.Linear:\n",
    "#         nn.init.xavier_uniform_(m.weight)\n",
    "# optimized_nn = optimized_nn.apply(init_normal)\n",
    "accuracy, loss_np, val_accuracy = train_val_NN(optimized_nn,train_loader, validation_loader, criterion, optimizer,num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy[-1])\n",
    "print(val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Accuracy Plot for Feedforward NN ##################################################\n",
    "\n",
    "# lst_acc = [accuracy[i].tolist()[0] for i in range(len(accuracy))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# f, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, lst_acc,marker = 'o')\n",
    "# ax.set_ylim(bottom=0)\n",
    "# plt.title('Plot showing the variations in accuracy for training set in the Baseline Feedforward NN over 40 epochs \\n')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.legend(['accuracy'])\n",
    "# plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################### Loss Plot for Feedforward NN ##################################################\n",
    "\n",
    "# lst_loss = [loss_np[i].tolist()[0] for i in range(len(accuracy))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# f, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, lst_loss, 'r', marker = 'o',)\n",
    "# ax.set_ylim(bottom=0)\n",
    "# plt.title('Plot showing the variations in loss for training set in the Baseline Feedforward NN over 40 epochs \\n')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.legend(['loss'])\n",
    "# plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Accuracy Plot for Convolutional NN ##############################################\n",
    "\n",
    "# lst_acc = [accuracy[i].tolist()[0] for i in range(len(accuracy))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# f, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, lst_acc,marker = 'o')\n",
    "# ax.set_ylim(bottom=0)\n",
    "# plt.title('Plot showing the variations in accuracy for training set in the Convolutional NN over 40 epochs \\n')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.legend(['accuracy'])\n",
    "# plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Loss Plot for Convolutional NN ##############################################\n",
    "\n",
    "# lst_loss = [loss_np[i].tolist()[0] for i in range(len(accuracy))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# f, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, lst_loss, 'r', marker = 'o',)\n",
    "# ax.set_ylim(bottom=0)\n",
    "# plt.title('Plot showing the variations in loss for training set in the Convolutional NN working on\\\n",
    "#            normalized images over 40 epochs \\n')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.legend(['loss'])\n",
    "# plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_acc = [accuracy[i].tolist()[0] for i in range(len(accuracy))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# f, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, lst_acc,marker = 'o')\n",
    "# ax.set_ylim(bottom=0,top = 0.7)\n",
    "# plt.title('Plot showing the variations in accuracy for training set in the Convolutional NN working on\\\n",
    "#  normalized images over 40 epochs \\n')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.legend(['accuracy'])\n",
    "# plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lst_loss = [loss_np[i].tolist()[0] for i in range(len(accuracy))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# f, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, lst_loss, 'r', marker = 'o',)\n",
    "# ax.set_ylim(bottom=0)\n",
    "# plt.title('Plot showing the variations in loss for training set in the Convolutional NN working on\\\n",
    "#  normalized images over 40 epochs \\n')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.legend(['loss'])\n",
    "# plt.show(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
