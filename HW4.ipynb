{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8JILDxrsgPY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms.functional as T\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data_utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import keras\n",
    "# from keras.layers import Input, merge\n",
    "# from keras.layers import Convolution2D , concatenate ,Conv2D,Dense\n",
    "# from keras.layers import Activation,Dropout, GlobalAveragePooling2D\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.utils import  to_categorical\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as tr\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#from google.colab import drive                IF you are using COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKixUdldszgx"
   },
   "outputs": [],
   "source": [
    "# Use this if you are working on COLAB\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HApL-cvBs1Ah"
   },
   "outputs": [],
   "source": [
    "def extract_data(x_data_filepath, y_data_filepath):\n",
    "    X = np.load(x_data_filepath)\n",
    "    y = np.load(y_data_filepath)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_mCkbFV1bq9"
   },
   "outputs": [],
   "source": [
    "def data_visualization(images,labels):\n",
    "    \"\"\"\n",
    "    Visualize 6 pictures per class using your prefered visulization library (matplotlib, etc)\n",
    "\n",
    "    Args:\n",
    "        images: training images in shape (num_images,3,image_H,image_W)\n",
    "        labels: training labels in shape (num_images,)\n",
    "    \"\"\"\n",
    "    label0=np.asarray(np.where(labels==0))\n",
    "    label1=np.asarray(np.where(labels==1))\n",
    "    label2=np.asarray(np.where(labels==2))\n",
    "    label3=np.asarray(np.where(labels==3))\n",
    "    label4=np.asarray(np.where(labels==4))\n",
    "    \n",
    "\n",
    "    train_img = images.transpose()\n",
    "    for i in range(6):\n",
    "        plt.figure()\n",
    "        print(i)\n",
    "        plt.imshow(train_img[:,:,:,label0[0][i]].swapaxes(-3,-2))\n",
    "        plt.figure()\n",
    "        plt.imshow(train_img[:,:,:,label1[0][i]].swapaxes(-3,-2))\n",
    "        plt.figure()\n",
    "        plt.imshow(train_img[:,:,:,label2[0][i]].swapaxes(-3,-2))\n",
    "        plt.figure()\n",
    "        plt.imshow(train_img[:,:,:,label3[0][i]].swapaxes(-3,-2))\n",
    "        plt.figure()\n",
    "        plt.imshow(train_img[:,:,:,label4[0][i]].swapaxes(-3,-2))\n",
    "        plt.show()\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnttiXoks2sn"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Extracting and loading data\n",
    "############################################################\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.len = len(X)           \n",
    "        if torch.cuda.is_available():\n",
    "            self.x_data = torch.from_numpy(X).float().cuda()\n",
    "            self.y_data = torch.from_numpy(y).long().cuda()\n",
    "        else:\n",
    "            self.x_data = torch.from_numpy(X).float()\n",
    "            self.y_data = torch.from_numpy(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2LxFInms4ks"
   },
   "outputs": [],
   "source": [
    "def create_validation(x_train,y_train):\n",
    "    \n",
    "    data = Dataset(x_train,y_train)\n",
    "    num_train = len(x_train)\n",
    "    indices = np.array((range(num_train)))\n",
    "    split =  int(np.round(0.8* num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx ,test_idx= indices[:split] , indices[split:]\n",
    "    new_x_train = data.x_data[train_idx]\n",
    "    new_y_train = data.y_data[train_idx]\n",
    "    x_val = data.x_data[test_idx]\n",
    "    y_val= data.y_data[test_idx]\n",
    "      \n",
    "    \n",
    "    return new_x_train.numpy(),new_y_train.numpy(),x_val.numpy(),y_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "812xDSEms72t"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Feed Forward Neural Network\n",
    "############################################################\n",
    "class FeedForwardNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.fc1 as the variable name for your first fully connected layer\n",
    "        (2) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(16320,2000)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2000,5)\n",
    "    def forward(self, x):\n",
    "        # input size is flattened \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_out = F.relu(self.fc1(x))\n",
    "        # using this layer input as output for the other \n",
    "        out = self.fc2(x_out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "    \"\"\" \n",
    "        Please do not change the functions below. \n",
    "        They will be used to test the correctness of your implementation \n",
    "    \"\"\"\n",
    "    def get_fc1_params(self):\n",
    "        return self.fc1.__repr__()\n",
    "    \n",
    "    def get_fc2_params(self):\n",
    "        return self.fc2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NXchxSvtEdz"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Convolutional Neural Network\n",
    "############################################################\n",
    "class ConvolutionalNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
    "        (2) Use self.pool1 as the variable name for your first pooling layer\n",
    "        (3) Use self.conv2 as the variable name for your second convolutional layer\n",
    "        (4) Use self.pool2 as the variable name for you second pooling layer  \n",
    "        (5) Use self.fc1 as the variable name for your first fully connected laye\n",
    "        (6) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3,3), stride=1, padding=0)\n",
    "       \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3  = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3) , stride = 1, padding = 0)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        size1= (32*14*19)\n",
    "        size2 = 3072\n",
    "        # for autograder , typed itin \n",
    "        self.fc1 = nn.Linear(8512, 200)\n",
    "        self.fc2 = nn.Linear(200,5)\n",
    "    def forward(self, x):\n",
    "        x_numpy_img = x.cpu().numpy()\n",
    "        x= normalize_image(x_numpy_img)\n",
    "        x.cuda()\n",
    "        # conv1\n",
    "#         out = self.conv1(x)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        #maxpool                     \n",
    "        out = self.pool1(out)\n",
    "        #conv2 \n",
    "#         out = self.conv2(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        #maxpool2\n",
    "        out = self.pool2(out)\n",
    "        #conv3 \n",
    "        out = F.relu(self.conv3(out))\n",
    "        #maxpool3\n",
    "        out = self.pool3(out)\n",
    "        \n",
    "        #out from conv is ()\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #droputlayer\n",
    "        out = self.dropout(out)\n",
    "        # fully connected 1 \n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "        #fully connected 2 \n",
    "        out =self.fc2(out)\n",
    "                               \n",
    "        return out\n",
    "      \n",
    "    \"\"\" \n",
    "        Please do not change the functions below. \n",
    "        They will be used to test the correctness of your implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_conv1_params(self):\n",
    "        return self.conv1.__repr__()\n",
    "    \n",
    "    def get_pool1_params(self):\n",
    "        return self.pool1.__repr__()\n",
    "\n",
    "    def get_conv2_params(self):\n",
    "        return self.conv2.__repr__()\n",
    "      \n",
    "    def get_pool2_params(self):\n",
    "        return self.pool2.__repr__()\n",
    "      \n",
    "    def get_fc1_params(self):\n",
    "        return self.fc1.__repr__()\n",
    "    \n",
    "    def get_fc2_params(self):\n",
    "        return self.fc2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5hhOy6htEtC"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize each input image\n",
    "\n",
    "    Args:\n",
    "    image: the input image in shape (3,image_H,image_W)\n",
    "    Returns:\n",
    "    norimg: the normalized image in the same shape as the input\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    img2 = image.copy()\n",
    "\n",
    "    rmean , rvar=  np.mean(img2[0 ,:,:]), np.std(img2[0 ,:,:])\n",
    "    gmean , gvar=  np.mean(img2[1,:,:]) , np.std(img2[1,:,:])\n",
    "    bmean , bvar=  np.mean(img2[2,:,:]), np.std(img2[2,:,:])\n",
    "#     image = image.cuda()\n",
    "    \n",
    "#     print(type(rmean))\n",
    "#     print(torch.tensor(image).dtype)\n",
    "    img2[0,:,:] = (img2[0,:,:] - rmean)/ rvar \n",
    "    img2[1,:,:] = (img2[1,:,:] - gmean)/ gvar \n",
    "    img2[2,:,:] = (img2[2,:,:] - bmean)/ bvar \n",
    "    \n",
    "    normig = torch.tensor(img2)\n",
    "#     normig= normig.type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    return normig.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVRyEtmQtzn2"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Optimized Neural Network\n",
    "############################################################\n",
    "class OptimizedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0)\n",
    "       \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3  = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3 , stride = 1, padding = 0)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        size= (32*14*19)     \n",
    "        self.fc1 = nn.Linear(3072, 200)\n",
    "        self.fc2 = nn.Linear(200,5)                \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_numpy_img = x.cpu().numpy()\n",
    "        x= normalize_image(x_numpy_img)\n",
    "        x.cuda()\n",
    "        # conv1\n",
    "#         out = self.conv1(x)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        #maxpool                     \n",
    "        out = self.maxpool1(out)\n",
    "        #conv2 \n",
    "#         out = self.conv2(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        #maxpool2\n",
    "        out = self.maxpool2(out)\n",
    "        #conv3 \n",
    "        out = F.relu(self.conv3(out))\n",
    "        #maxpool3\n",
    "        out = self.maxpool3(out)\n",
    "        \n",
    "        #out from conv is ()\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #droputlayer\n",
    "        out = self.dropout(out)\n",
    "        # fully connected 1 \n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "        #fully connected 2 \n",
    "        out =self.fc2(out)        \n",
    "        return out\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQHzqYLSt-mQ"
   },
   "outputs": [],
   "source": [
    "def train_val_NN(neural_network, train_loader, validation_loader, loss_function, optimizer,num_epochs):\n",
    "    correct =0 \n",
    "    correct_val = 0\n",
    "    loss_np = np.zeros((num_epochs,1))\n",
    "    train_loss = []\n",
    "    valid_loss=[]\n",
    "    accuracy = np.zeros((num_epochs+1,1))\n",
    "    val_accuracy=np.zeros((num_epochs+1,1))\n",
    "    i=0\n",
    "    \n",
    "    \n",
    "    for epoch in range(0,num_epochs+1): \n",
    "        correct =0 \n",
    "        correct_val = 0\n",
    "        temp_acc =0\n",
    "        \n",
    "    ## training part \n",
    "        neural_network.train()\n",
    "        for data, target in train_loader:\n",
    "#             print(data.shape)\n",
    "            optimizer.zero_grad()\n",
    "            output = neural_network(data)\n",
    "#             print(output.is_cuda)\n",
    "            target =target.cuda()\n",
    "            target = target.long()\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "        neural_network.eval()\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            output = neural_network(data)\n",
    "            loss = loss_function(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "#             print(output.is_cuda)\n",
    "            pred = output.cpu()\n",
    "            pred = pred.data.max(1, keepdim=True)[1]\n",
    "#             print(pred.is_cuda)\n",
    "            target1 = target.cpu()\n",
    "            correct_val += pred.eq(target1.data.view_as(pred)).sum()\n",
    "        print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))\n",
    "    \n",
    "        temp_acc =correct.item()/len(train_loader.dataset)\n",
    "        accuracy[i]= temp_acc\n",
    "        loss_np = valid_loss\n",
    "        train_loss\n",
    "        temp_val_acc =correct_val.item()/len(test_loader.dataset)\n",
    "        val_accuracy[i]= temp_val_acc\n",
    "        i+=1\n",
    "    return accuracy,loss_np,val_accuracy, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLlMhNt7vQxR"
   },
   "outputs": [],
   "source": [
    "def test_NN(neural_network, test_loader):\n",
    "  \n",
    "    \n",
    "    #taking testloader and getting each image \n",
    "    \n",
    "    neural_network.eval()\n",
    "    Preds = torch.LongTensor().cuda()\n",
    "    for i, images in enumerate(test_loader):\n",
    "        # each time one image is printed in testloader \n",
    "        data= images\n",
    "#         print(data.shape)\n",
    "        output = neural_network(data)\n",
    "       # print(data.shape)\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "#         print(pred.is_cuda)\n",
    "        Preds = torch.cat((Preds, pred), dim = 0 )\n",
    "        \n",
    "    \n",
    "    return Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for test and making prediction file \n",
    "\n",
    "# test_images = np.load('data/images_test.npy')\n",
    "# print(test_images.shape)\n",
    "# test_loader = torch.utils.data.DataLoader(test_images , batch_size = 64, shuffle=False)\n",
    "# Preds = test_NN(nnk, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('HW4_preds.txt','w',encoding = 'utf8') as file:\n",
    "#     for i in range(len(test_loader.dataset)):\n",
    "#         file.write(str(Preds[i].item()))\n",
    "#         file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDQrfJXSv9iY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Runnig Optimized Neural Network \n",
    "\n",
    "# run the optimized nueral network\n",
    "# torch.cuda.empty_cache()\n",
    "# images ,labels = extract_data( 'data/images_train.npy','data/labels_train.npy')\n",
    "\n",
    "# new_x_train,new_y_train,x_val, y_val = create_validation(images,labels)\n",
    "\n",
    "# print(type(new_x_train))\n",
    "# print(type(new_y_train))\n",
    "\n",
    "# train = torch.utils.data.TensorDataset(new_x_train,new_y_train)\n",
    "# test = torch.utils.data.TensorDataset(x_val,y_val)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train, batch_size=64)\n",
    "# test_loader = torch.utils.data.DataLoader(test, batch_size=64)\n",
    "\n",
    "\n",
    "# neural_network = OptimizedNN()\n",
    "# neural_network=neural_network.cuda()\n",
    "# loss_function = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# optimizer = torch.optim.Adam(neural_network.parameters(),lr =0.001)\n",
    "# num_epochs = 40\n",
    "\n",
    "\n",
    "\n",
    "# acc, los , val_acc = train_val_NN(neural_network, train_loader, test_loader, loss_function, optimizer,num_epochs)\n",
    "\n",
    "# print(acc[-1])\n",
    "# print(val_acc[-1])\n",
    "# print(np.mean(acc))\n",
    "# print(np.mean(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting the loss \n",
    "# fig = plt.figure()\n",
    "# ax = plt.subplot(111)\n",
    "# ax.plot(t, val_accs_np[:-1], marker='x')\n",
    "# # ax.plot(t, loss_np, label='Validation-Accuracy with normalization')\n",
    "# plt.title('Loss on Validation ')\n",
    "# ax.legend()\n",
    "# ax.set_xlabel('Epochs')\n",
    "# plt.show()\n",
    "# print(val_accs[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gojhzqhrwAxk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ioni3nPfwEIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
